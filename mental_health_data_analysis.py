# -*- coding: utf-8 -*-
"""mental-health-data-analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VPzBA_4nuXytRLZmUtm_yTZBojjc2dN6
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Embedding
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Load dataset
data_path = '/content/drive/MyDrive/Colab Notebooks/mental_health.csv'
data = pd.read_csv(data_path)

# Display basic information about the dataset
print(data.info())
print(data.head())

# Check for missing values
print(data.isnull().sum())

# Basic preprocessing (Assuming text and label columns exist)
data = data.dropna()
X = data['text']
y = data['label']

# Encode labels (if not already encoded as integers)
encoder = LabelEncoder()
y = encoder.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tokenization and padding
max_words = 10000
max_len = 100

# Tokenizer
tokenizer = keras.preprocessing.text.Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_len, padding='post')
X_test_pad = keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_len, padding='post')

# Model 1: Dense Neural Network
def build_dense_model():
    model = Sequential([
        Dense(128, activation='relu', input_shape=(max_len,)),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Model 2: Convolutional Neural Network (CNN)
def build_cnn_model():
    model = Sequential([
        Embedding(max_words, 128, input_length=max_len),
        Conv1D(64, 5, activation='relu'),
        MaxPooling1D(pool_size=2),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Model 3: LSTM
def build_lstm_model():
    model = Sequential([
        Embedding(max_words, 128, input_length=max_len),
        LSTM(64, return_sequences=False),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Function to plot confusion matrix
def plot_confusion_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix for {model_name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# Train and evaluate models
models = {'Dense': build_dense_model(), 'CNN': build_cnn_model(), 'LSTM': build_lstm_model()}

history = {}
for name, model in models.items():
    print(f"Training {name} model...")
    hist = model.fit(X_train_pad, y_train, epochs=5, validation_split=0.2, batch_size=32)
    history[name] = hist
    print(f"Evaluating {name} model...")
    y_pred = (model.predict(X_test_pad) > 0.5).astype('int32')
    print(classification_report(y_test, y_pred))
    plot_confusion_matrix(y_test, y_pred, name)

# Plot accuracy curves
plt.figure(figsize=(10, 6))
for name, hist in history.items():
    plt.plot(hist.history['accuracy'], label=f'{name} Train Accuracy')
    plt.plot(hist.history['val_accuracy'], label=f'{name} Val Accuracy')
plt.legend()
plt.title('Model Accuracy Comparison')
plt.show()